{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install skll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import multi_gpu_model\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# config = tf.ConfigProto(device_count={\"CPU\": 8,\"GPU\":0})\n",
    "# keras.backend.tensorflow_backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8410855416115645961\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 1605077269828070216\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 16507576182715105756\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7906669364\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 17337649548598762880\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1070 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, test_data_size):\n",
    "    \"\"\"\n",
    "    Split data into test and training datasets.\n",
    "\n",
    "    INPUT\n",
    "        X: NumPy array of arrays\n",
    "        y: Pandas series, which are the labels for input array X\n",
    "        test_data_size: size of test/train split. Value from 0 to 1\n",
    "\n",
    "    OUPUT\n",
    "        Four arrays: X_train, X_test, y_train, and y_test\n",
    "    \"\"\"\n",
    "    return train_test_split(X, y, test_size=test_data_size, random_state=42)\n",
    "\n",
    "\n",
    "def reshape_data(arr, img_rows, img_cols, channels):\n",
    "    \"\"\"\n",
    "    Reshapes the data into format for CNN.\n",
    "\n",
    "    INPUT\n",
    "        arr: Array of NumPy arrays.\n",
    "        img_rows: Image height\n",
    "        img_cols: Image width\n",
    "        channels: Specify if the image is grayscale (1) or RGB (3)\n",
    "\n",
    "    OUTPUT\n",
    "        Reshaped array of NumPy arrays.\n",
    "    \"\"\"\n",
    "    return arr.reshape(arr.shape[0], img_rows, img_cols, channels)\n",
    "\n",
    "\n",
    "def cnn_model(X_train, y_train, kernel_size, nb_filters, channels, nb_epoch, batch_size, nb_classes, nb_gpus):\n",
    "    \"\"\"\n",
    "    Define and run the Convolutional Neural Network\n",
    "\n",
    "    INPUT\n",
    "        X_train: Array of NumPy arrays\n",
    "        X_test: Array of NumPy arrays\n",
    "        y_train: Array of labels\n",
    "        y_test: Array of labels\n",
    "        kernel_size: Initial size of kernel\n",
    "        nb_filters: Initial number of filters\n",
    "        channels: Specify if the image is grayscale (1) or RGB (3)\n",
    "        nb_epoch: Number of epochs\n",
    "        batch_size: Batch size for the model\n",
    "        nb_classes: Number of classes for classification\n",
    "\n",
    "    OUTPUT\n",
    "        Fitted CNN model\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(nb_filters, (kernel_size[0], kernel_size[1]),\n",
    "                     padding='valid',\n",
    "                     strides=1,\n",
    "                     input_shape=(img_rows, img_cols, channels), activation=\"relu\"))\n",
    "\n",
    "    model.add(Conv2D(nb_filters, (kernel_size[0], kernel_size[1]), activation=\"relu\"))\n",
    "\n",
    "    model.add(Conv2D(nb_filters, (kernel_size[0], kernel_size[1]), activation=\"relu\"))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    print(\"Model flattened out to: \", model.output_shape)\n",
    "\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    #model = multi_gpu_model(model, gpus=nb_gpus)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    stop = EarlyStopping(monitor='val_acc',\n",
    "                         min_delta=0.001,\n",
    "                         patience=2,\n",
    "                         verbose=0,\n",
    "                         mode='auto')\n",
    "\n",
    "    tensor_board = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=nb_epoch,\n",
    "              verbose=1,\n",
    "              validation_split=0.2,\n",
    "              class_weight='auto',\n",
    "              callbacks=[stop, tensor_board])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def save_model(model, score, model_name):\n",
    "    \"\"\"\n",
    "    Saves Keras model to an h5 file, based on precision_score\n",
    "\n",
    "    INPUT\n",
    "        model: Keras model object to be saved\n",
    "        score: Score to determine if model should be saved.\n",
    "        model_name: name of model to be saved\n",
    "    \"\"\"\n",
    "\n",
    "    if score >= 0.75:\n",
    "        print(\"Saving Model\")\n",
    "        model.save(\"models/\" + model_name + \"_recall_\" + str(round(score, 4)) + \".h5\")\n",
    "    else:\n",
    "        print(\"Model Not Saved.  Score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify parameters before model is run.\n",
    "batch_size = 64\n",
    "\n",
    "nb_classes = 2\n",
    "nb_epoch = 30\n",
    "\n",
    "img_rows, img_cols = 256, 256\n",
    "channels = 3\n",
    "nb_filters = 32\n",
    "kernel_size = (8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "labels = pd.read_csv(\"0X_trainLabels_master_256_v2.csv\")\n",
    "X = np.load(\"0X_train.npy\")\n",
    "y = np.array([1 if l >= 1 else 0 for l in labels['level']])\n",
    "# y = np.array(labels['level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into test/ train datasets\n"
     ]
    }
   ],
   "source": [
    "print(\"Splitting data into test/ train datasets\")\n",
    "X_train, X_test, y_train, y_test = split_data(X, y, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaping Data\n",
      "X_train Shape:  (42554, 256, 256, 3)\n",
      "X_test Shape:  (10639, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Reshaping Data\")\n",
    "X_train = reshape_data(X_train, img_rows, img_cols, channels)\n",
    "X_test = reshape_data(X_test, img_rows, img_cols, channels)\n",
    "\n",
    "print(\"X_train Shape: \", X_train.shape)\n",
    "print(\"X_test Shape: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_split = np.array_split(X_train, 20)\n",
    "# nx_train = []\n",
    "# for i in range(0,len(df_split)):\n",
    "#     nx_train.append(df_split[i].astype('float32'))\n",
    "#     df_split[i] = 0 \n",
    "#     print(nx_train[i].shape)\n",
    "    \n",
    "# del df_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = np.hstack(nx_train[0], nx_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing Data\n"
     ]
    }
   ],
   "source": [
    "input_shape = (img_rows, img_cols, channels)\n",
    "\n",
    "print(\"Normalizing Data\")\n",
    "X_train = X_train.astype('float16')\n",
    "X_test = X_test.astype('float16')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train Shape:  (42554, 2)\n",
      "y_test Shape:  (10639, 2)\n"
     ]
    }
   ],
   "source": [
    "y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "print(\"y_train Shape: \", y_train.shape)\n",
    "print(\"y_test Shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model\n",
      "Model flattened out to:  (None, 438048)\n",
      "Train on 34043 samples, validate on 8511 samples\n",
      "Epoch 1/30\n",
      "34043/34043 [==============================] - 306s 9ms/step - loss: 0.7602 - acc: 0.5086 - val_loss: 0.6919 - val_acc: 0.5277\n",
      "Epoch 2/30\n",
      "34043/34043 [==============================] - 300s 9ms/step - loss: 0.6978 - acc: 0.5151 - val_loss: 0.6942 - val_acc: 0.5277\n",
      "Epoch 3/30\n",
      "34043/34043 [==============================] - 301s 9ms/step - loss: 0.6937 - acc: 0.5173 - val_loss: 0.6920 - val_acc: 0.5277\n",
      "Predicting\n",
      "Test score: 0.6921419195521986\n",
      "Test accuracy: 0.5245793777834776\n",
      "Precision:  0.5245793777610678\n",
      "Recall:  1.0\n",
      "Saving Model\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Model\")\n",
    "\n",
    "model = cnn_model(X_train, y_train, kernel_size, nb_filters, channels, nb_epoch, batch_size,nb_classes, nb_gpus=1)\n",
    "\n",
    "print(\"Predicting\")\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "\n",
    "save_model(model=model, score=recall, model_name=\"DR_Two_Classes\")\n",
    "print(\"Completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
