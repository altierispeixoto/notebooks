{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import lightgbm as lgb\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from hyperopt import STATUS_OK\n",
    "from hyperopt import hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Dataset to play with it\n",
    "train= pd.read_csv(\"/home/altieris/datascience/data/santander-customer-transaction-prediction/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=[\"target\",\"ID_code\"]\n",
    "\n",
    "drop_from_shap=['var_185', 'var_181', 'var_182', 'var_183', 'var_14', 'var_41',\n",
    "       'var_98', 'var_103', 'var_189', 'var_10', 'var_7', 'var_64',\n",
    "       'var_65', 'var_84', 'var_73', 'var_79', 'var_96', 'var_19',\n",
    "       'var_17', 'var_160', 'var_143', 'var_46', 'var_153', 'var_39',\n",
    "       'var_38', 'var_37', 'var_158', 'var_136', 'var_161', 'var_42',\n",
    "       'var_129', 'var_30', 'var_29', 'var_126', 'var_124', 'var_27',\n",
    "       'var_117', 'var_59', 'var_100','var_168', 'var_3', 'var_8', 'var_74', 'var_72', 'var_178',\n",
    "       'var_54', 'var_171', 'var_50', 'var_152', 'var_55', 'var_140',\n",
    "       'var_138', 'var_193', 'var_156', 'var_113', 'var_63', 'var_15',\n",
    "       'var_60', 'var_69', 'var_159', 'var_47', 'var_61', 'var_176',\n",
    "       'var_68', 'var_16', 'var_57', 'var_101', 'var_25', 'var_120','var_194', 'var_11', 'var_45', 'var_196', 'var_83', 'var_20',\n",
    "       'var_77', 'var_134', 'var_82', 'var_102', 'var_97', 'var_187',\n",
    "       'var_142', 'var_88', 'var_62', 'var_4']\n",
    "\n",
    "train_x = train.drop(cols,axis=1).drop(drop_from_shap,axis=1)\n",
    "train_y = train[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from hyperopt import STATUS_OK\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "def objective(params, n_folds = N_FOLDS):\n",
    "    \"\"\"Objective function for Gradient Boosting Machine Hyperparameter Optimization\"\"\"\n",
    "    \n",
    "    # Keep track of evals\n",
    "    global ITERATION\n",
    "    \n",
    "    ITERATION += 1\n",
    "    \n",
    "    # Retrieve the subsample if present otherwise set to 1.0\n",
    "    subsample = params['boosting_type'].get('subsample', 1.0)\n",
    "    \n",
    "    # Extract the boosting type\n",
    "    params['boosting_type'] = params['boosting_type']['boosting_type']\n",
    "    params['subsample'] = subsample\n",
    "    \n",
    "    # Make sure parameters that need to be integers are integers\n",
    "    for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n",
    "        params[parameter_name] = int(params[parameter_name])\n",
    "    \n",
    "    start = timer()\n",
    "    \n",
    "    # Perform n_folds cross validation\n",
    "    cv_results = lgb.cv(params, train_set, num_boost_round = 10000, nfold = n_folds, \n",
    "                        early_stopping_rounds = 100, metrics = 'auc', seed = 50)\n",
    "    \n",
    "    run_time = timer() - start\n",
    "    \n",
    "    # Extract the best score\n",
    "    best_score = np.max(cv_results['auc-mean'])\n",
    "    \n",
    "    # Loss must be minimized\n",
    "    loss = 1 - best_score\n",
    "    \n",
    "    # Boosting rounds that returned the highest cv score\n",
    "    n_estimators = int(np.argmax(cv_results['auc-mean']) + 1)\n",
    "\n",
    "    # Write to the csv file ('a' means append)\n",
    "    of_connection = open(out_file, 'a')\n",
    "    writer = csv.writer(of_connection)\n",
    "    writer.writerow([loss, params, ITERATION, n_estimators, run_time])\n",
    "    \n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': loss, 'params': params, 'iteration': ITERATION,\n",
    "            'estimators': n_estimators, \n",
    "            'train_time': run_time, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space\n",
    "space = {\n",
    "    'class_weight': hp.choice('class_weight', [None, 'balanced']),\n",
    "    'boosting_type': hp.choice('boosting_type', \n",
    "                               [{'boosting_type': 'gbdt', \n",
    "                                    'subsample': hp.uniform('gdbt_subsample', 0.5, 1)}, \n",
    "                                 {'boosting_type': 'dart', \n",
    "                                     'subsample': hp.uniform('dart_subsample', 0.5, 1)},\n",
    "                                 {'boosting_type': 'goss'}]),\n",
    "    'num_leaves': hp.quniform('num_leaves', 30, 150, 1),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "    'subsample_for_bin': hp.quniform('subsample_for_bin', 20000, 300000, 20000),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 20, 500, 5),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import Trials\n",
    "\n",
    "# Keep track of results\n",
    "bayes_trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File to save first results\n",
    "out_file = 'gbm_trials.csv'\n",
    "of_connection = open(out_file, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "\n",
    "# Write the headers to the file\n",
    "writer.writerow(['loss', 'params', 'iteration', 'estimators', 'train_time'])\n",
    "of_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tpe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-705c8b24250c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Run optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m best = fmin(fn = objective, space = space, algo = tpe.suggest, \n\u001b[0m\u001b[1;32m      9\u001b[0m             max_evals = MAX_EVALS, trials = bayes_trials, rstate = np.random.RandomState(50))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tpe' is not defined"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "\n",
    "# Global variable\n",
    "global  ITERATION\n",
    "\n",
    "ITERATION = 0\n",
    "\n",
    "# Run optimization\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, \n",
    "            max_evals = MAX_EVALS, trials = bayes_trials, rstate = np.random.RandomState(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the trials with lowest loss (highest AUC) first\n",
    "bayes_trials_results = sorted(bayes_trials.results, key = lambda x: x['loss'])\n",
    "bayes_trials_results[:2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
