{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from catboost import CatBoostClassifier,Pool\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Dataset to play with it\n",
    "train= pd.read_csv(\"/home/altieris/datascience/data/santander-customer-transaction-prediction/train.csv\")\n",
    "test = pd.read_csv('/home/altieris/datascience/data/santander-customer-transaction-prediction/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=[\"target\",\"ID_code\"]\n",
    "X = train.drop(cols,axis=1)\n",
    "y = train[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test  = test.drop(\"ID_code\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for get better result chage fold_n to 5\n",
    "fold_n=5\n",
    "folds = StratifiedKFold(n_splits=fold_n, shuffle=True, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <a id=\"6\"></a> <br>\n",
    "# 6- Model Development\n",
    "So far, we have used two  models, and at this point we add another model and we'll be expanding it soon.\n",
    "in this section you will see following model:\n",
    "1. lightgbm\n",
    "1. RandomForestClassifier\n",
    "1. DecisionTreeClassifier\n",
    "1. CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-1 lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on following kernel https://www.kaggle.com/dromosys/sctp-working-lgb\n",
    "params = {'num_leaves': 9,\n",
    "         'min_data_in_leaf': 42,\n",
    "         'objective': 'binary',\n",
    "         'max_depth': 16,\n",
    "         'learning_rate': 0.0123,\n",
    "         'boosting': 'gbdt',\n",
    "         'bagging_freq': 5,\n",
    "         'bagging_fraction': 0.8,\n",
    "         'feature_fraction': 0.8201,\n",
    "         'bagging_seed': 11,\n",
    "         'reg_alpha': 1.728910519108444,\n",
    "         'reg_lambda': 4.9847051755586085,\n",
    "         'random_state': 42,\n",
    "         'metric': 'auc',\n",
    "         'verbosity': -1,\n",
    "         'subsample': 0.81,\n",
    "         'min_gain_to_split': 0.01077313523861969,\n",
    "         'min_child_weight': 19.428902804238373,\n",
    "         'num_threads': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Thu Mar  7 23:34:00 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[300]\ttraining's auc: 0.833564\tvalid_1's auc: 0.811675\n",
      "[600]\ttraining's auc: 0.867848\tvalid_1's auc: 0.84136\n",
      "[900]\ttraining's auc: 0.885227\tvalid_1's auc: 0.856314\n",
      "[1200]\ttraining's auc: 0.896729\tvalid_1's auc: 0.86598\n",
      "[1500]\ttraining's auc: 0.904799\tvalid_1's auc: 0.872299\n",
      "[1800]\ttraining's auc: 0.911206\tvalid_1's auc: 0.877422\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's auc: 0.914416\tvalid_1's auc: 0.879595\n",
      "Fold 1 started at Thu Mar  7 23:35:16 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[300]\ttraining's auc: 0.831021\tvalid_1's auc: 0.821954\n",
      "[600]\ttraining's auc: 0.866447\tvalid_1's auc: 0.853076\n",
      "[900]\ttraining's auc: 0.884155\tvalid_1's auc: 0.867669\n",
      "[1200]\ttraining's auc: 0.895765\tvalid_1's auc: 0.876575\n",
      "[1500]\ttraining's auc: 0.903851\tvalid_1's auc: 0.882447\n",
      "[1800]\ttraining's auc: 0.909834\tvalid_1's auc: 0.886699\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's auc: 0.913122\tvalid_1's auc: 0.8887\n",
      "Fold 2 started at Thu Mar  7 23:36:31 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[300]\ttraining's auc: 0.834686\tvalid_1's auc: 0.814443\n",
      "[600]\ttraining's auc: 0.867543\tvalid_1's auc: 0.844016\n",
      "[900]\ttraining's auc: 0.884992\tvalid_1's auc: 0.859454\n",
      "[1200]\ttraining's auc: 0.896091\tvalid_1's auc: 0.869293\n",
      "[1500]\ttraining's auc: 0.903919\tvalid_1's auc: 0.875875\n",
      "[1800]\ttraining's auc: 0.910025\tvalid_1's auc: 0.880709\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's auc: 0.91331\tvalid_1's auc: 0.883163\n",
      "Fold 3 started at Thu Mar  7 23:37:50 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[300]\ttraining's auc: 0.832615\tvalid_1's auc: 0.813789\n",
      "[600]\ttraining's auc: 0.866655\tvalid_1's auc: 0.846097\n",
      "[900]\ttraining's auc: 0.88437\tvalid_1's auc: 0.862167\n",
      "[1200]\ttraining's auc: 0.895877\tvalid_1's auc: 0.871873\n",
      "[1500]\ttraining's auc: 0.904099\tvalid_1's auc: 0.878405\n",
      "[1800]\ttraining's auc: 0.910077\tvalid_1's auc: 0.882914\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's auc: 0.91334\tvalid_1's auc: 0.88516\n",
      "Fold 4 started at Thu Mar  7 23:39:11 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[300]\ttraining's auc: 0.832663\tvalid_1's auc: 0.818737\n",
      "[600]\ttraining's auc: 0.86705\tvalid_1's auc: 0.84887\n",
      "[900]\ttraining's auc: 0.884615\tvalid_1's auc: 0.862812\n",
      "[1200]\ttraining's auc: 0.89615\tvalid_1's auc: 0.871995\n",
      "[1500]\ttraining's auc: 0.904265\tvalid_1's auc: 0.877813\n",
      "[1800]\ttraining's auc: 0.91019\tvalid_1's auc: 0.882188\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's auc: 0.913645\tvalid_1's auc: 0.884532\n",
      "CPU times: user 25min 59s, sys: 5.1 s, total: 26min 4s\n",
      "Wall time: 6min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred_lgb = np.zeros(len(X_test))\n",
    "for fold_n, (train_index, valid_index) in enumerate(folds.split(X,y)):\n",
    "    print('Fold', fold_n, 'started at', time.ctime())\n",
    "    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "        \n",
    "    lgb_model = lgb.train(params,train_data,num_boost_round=2000,#change 20 to 2000\n",
    "                    valid_sets = [train_data, valid_data],verbose_eval=300,early_stopping_rounds = 200)##change 10 to 200\n",
    "            \n",
    "    y_pred_lgb += lgb_model.predict(X_test, num_iteration=lgb_model.best_iteration)/5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <a id=\"64\"></a> <br>\n",
    "## 6-4 CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pool = Pool(train_X,train_y)\n",
    "cat_model = CatBoostClassifier(\n",
    "                               iterations=3000,# change 25 to 3000 to get best performance \n",
    "                               learning_rate=0.03,\n",
    "                               objective=\"Logloss\",\n",
    "                               eval_metric='AUC',\n",
    "                              )\n",
    "cat_model.fit(train_X,train_y,silent=True)\n",
    "y_pred_cat = cat_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can change your model and submit the results of other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_cat = pd.DataFrame({\n",
    "        \"ID_code\": test[\"ID_code\"],\n",
    "        \"target\": y_pred_cat\n",
    "    })\n",
    "submission_cat.to_csv('submission_cat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_lgb = pd.DataFrame({\n",
    "        \"ID_code\": test[\"ID_code\"],\n",
    "        \"target\": y_pred_lgb\n",
    "    })\n",
    "submission_lgb.to_csv('submission_lgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
