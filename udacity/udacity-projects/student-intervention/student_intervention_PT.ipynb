{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nanodegree Engenheiro de Machine Learning\n",
    "## Aprendizagem Supervisionada\n",
    "## Project 2: Construindo um Sistema de Intervenção para Estudantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bem-vindo ao segundo projeto do Nanodegree de Machine Learning! Neste Notebook, alguns templates de código já foram fornecidos, e será o seu trabalho implementar funcionalidades necessárias para completar este projeto com êxito. Seções que começam com **'Implementação'** no cabeçalho indicam que o bloco de código que se segue precisará de funcionalidades adicionais que você deve fornecer. Instruções serão providenciadas para cada seção e as especificações para cada implementação estarão marcadas no bloco de código com o comando `'TODO'`. Tenha certeza de ler atentamente todas as instruções!\n",
    "\n",
    "Além do código implementado, haverá questões relacionadas ao projeto e à implementação que você deve responder. Cada seção em que você tem que responder uma questão será antecedida de um cabeçalho **'Questão X'**. Leia atentamente cada questão e escreva respostas completas nas caixas de texto subsequentes que começam com **'Resposta: '**. O projeto enviado será avaliado baseado nas respostas para cada questão e a implementação que você forneceu.  \n",
    "\n",
    ">**Nota:** Células de código e Markdown podem ser executadas utilizando o atalho de teclado **Shift + Enter**. Além disso, as células Markdown podem ser editadas, um clique duplo na célula entra no modo de edição."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 1 - Classificação versus Regressão\n",
    "*Seu objetivo neste projeto é identificar estudantes que possam precisar de intervenção antecipada antes de serem reprovados. Que tipo de problema de aprendizagem supervisionada é esse: classificação ou regressão? Por quê?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: **\n",
    "\n",
    "Este é um caso que pode ser solucionado através de classificação, uma vez que se deseja categorizar os alunos que precisam de intervenção antecipada ou não."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observando os Dados\n",
    "Execute a célula de código abaixo para carregar as bibliotecas de Python necessárias e os dados sobre os estudantes. Note que a última coluna desse conjunto de dados, `'passed'`, será nosso rótulo alvo (se o aluno foi ou não aprovado). As outras colunas são atributos sobre cada aluno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob     Fjob  \\\n",
      "0     GP   F   18       U     GT3       A     4     4  at_home  teacher   \n",
      "1     GP   F   17       U     GT3       T     1     1  at_home    other   \n",
      "\n",
      "   ...   internet romantic  famrel  freetime  goout Dalc Walc health absences  \\\n",
      "0  ...         no       no       4         3      4    1    1      3        6   \n",
      "1  ...        yes       no       5         3      3    1    1      3        4   \n",
      "\n",
      "  passed  \n",
      "0     no  \n",
      "1     no  \n",
      "\n",
      "[2 rows x 31 columns]\n",
      "Os dados dos estudantes foram lidos com êxito!\n"
     ]
    }
   ],
   "source": [
    "# Importar bibliotecas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Ler os dados dos estudantes\n",
    "student_data = pd.read_csv(\"student-data.csv\")\n",
    "\n",
    "#Set PANDAS to show all columns in DataFrame\n",
    "#pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(student_data.head(2)) \n",
    "#print(student_data.describe())\n",
    "\n",
    "print(\"Os dados dos estudantes foram lidos com êxito!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Observando os Dados\n",
    "Vamos começar observando o conjunto de dados para determinar quantos são os estudantes sobre os quais temos informações e entender a taxa de graduação entre esses estudantes. Na célula de código abaixo, você vai precisar calcular o seguinte:\n",
    "- O número total de estudantes, `n_students`.\n",
    "- O número total de atributos para cada estudante, `n_features`.\n",
    "- O número de estudantes aprovados, `n_passed`.\n",
    "- O número de estudantes reprovados, `n_failed`.\n",
    "- A taxa de graduação da classe, `grad_rate`, em porcentagem (%).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número total de estudantes: 395\n",
      "Número de atributos: 30\n",
      "Número de estudantes aprovados: 265\n",
      "Número de estudantes reprovados: 130\n",
      "Taxa de graduação: 67.09%\n"
     ]
    }
   ],
   "source": [
    "# Calcule o número de estudante\n",
    "n_students = student_data.shape[0]\n",
    "\n",
    "# Calcule o número de atributos\n",
    "# Uma das colunas em student_data é a variável-alvo, e não um atributo. \n",
    "n_features = student_data.drop('passed', axis=1).shape[1]\n",
    "\n",
    "# Calcule o número de alunos aprovados\n",
    "n_passed = student_data[student_data.passed == 'yes'].shape[0]\n",
    "\n",
    "# Calcule o número de alunos reprovados\n",
    "n_failed = student_data[student_data.passed == 'no'].shape[0]\n",
    "\n",
    "# Calcule a taxa de graduação\n",
    "grad_rate = (n_passed * 100) / n_students\n",
    "\n",
    "# Imprima os resultados\n",
    "print(\"Número total de estudantes: {}\".format(n_students))\n",
    "print(\"Número de atributos: {}\".format(n_features))\n",
    "print(\"Número de estudantes aprovados: {}\".format(n_passed))\n",
    "print(\"Número de estudantes reprovados: {}\".format(n_failed))\n",
    "print(\"Taxa de graduação: {:.2f}%\".format(grad_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando os Dados\n",
    "Nesta seção, vamos preparar os dados para modelagem, treinamento e teste.\n",
    "\n",
    "### Identificar atributos e variáveis-alvo\n",
    "É comum que os dados que você obteve contenham atributos não numéricos. Isso pode ser um problema, dado que a maioria dos algoritmos de machine learning esperam dados númericos para operar cálculos.\n",
    "\n",
    "Execute a célula de código abaixo para separar os dados dos estudantes em atributos e variáveis-alvo e verificar se algum desses atributos é não numérico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas de atributos:\n",
      "['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n",
      "\n",
      "Coluna-alvo: passed\n",
      "\n",
      "Feature values:\n",
      "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\n",
      "0     GP   F   18       U     GT3       A     4     4  at_home   teacher   \n",
      "1     GP   F   17       U     GT3       T     1     1  at_home     other   \n",
      "2     GP   F   15       U     LE3       T     1     1  at_home     other   \n",
      "3     GP   F   15       U     GT3       T     4     2   health  services   \n",
      "4     GP   F   16       U     GT3       T     3     3    other     other   \n",
      "\n",
      "    ...    higher internet  romantic  famrel  freetime goout Dalc Walc health  \\\n",
      "0   ...       yes       no        no       4         3     4    1    1      3   \n",
      "1   ...       yes      yes        no       5         3     3    1    1      3   \n",
      "2   ...       yes      yes        no       4         3     2    2    3      3   \n",
      "3   ...       yes      yes       yes       3         2     2    1    1      5   \n",
      "4   ...       yes       no        no       4         3     2    1    2      5   \n",
      "\n",
      "  absences  \n",
      "0        6  \n",
      "1        4  \n",
      "2       10  \n",
      "3        2  \n",
      "4        4  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extraia as colunas dos atributo\n",
    "feature_cols = list(student_data.columns[:-1])\n",
    "\n",
    "# Extraia a coluna-alvo, 'passed'\n",
    "target_col = student_data.columns[-1] \n",
    "\n",
    "# Mostre a lista de colunas\n",
    "print(\"Colunas de atributos:\\n{}\".format(feature_cols))\n",
    "print(\"\\nColuna-alvo: {}\".format(target_col))\n",
    "\n",
    "# Separe os dados em atributos e variáveis-alvo (X_all e y_all, respectivamente)\n",
    "X_all = student_data[feature_cols]\n",
    "y_all = student_data[target_col]\n",
    "\n",
    "# Mostre os atributos imprimindo as cinco primeiras linhas\n",
    "print(\"\\nFeature values:\")\n",
    "print(X_all.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processar Colunas de Atributo\n",
    "\n",
    "Como você pode ver, há muitas colunas não numéricas que precisam ser convertidas! Muitas delas são simplesmente `yes`/`no`, por exemplo, a coluna `internet`. É razoável converter essas variáveis em valores (binários) `1`/`0`.\n",
    "\n",
    "Outras colunas, como `Mjob` e `Fjob`, têm mais do que dois valores e são conhecidas como variáveis categóricas. A maneira recomendada de lidar com esse tipo de coluna é criar uma quantidade de colunas proporcional aos possíveis valores (por exemplo, `Fjob_teacher`, `Fjob_other`, `Fjob_services`, etc), e assinalar `1` para um deles e `0` para todos os outros.\n",
    "\n",
    "Essas colunas geradas são por vezes chamadas de _variáveis postiças_ (em inglês: _dummy variables_), e nós iremos utilizar a função [`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies) para fazer essa conversão. Execute a célula de código abaixo para executar a rotina de pré-processamento discutida nesta seção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (48 total features):\n",
      "['school_GP', 'school_MS', 'sex_F', 'sex_M', 'age', 'address_R', 'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T', 'Medu', 'Fedu', 'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_father', 'guardian_mother', 'guardian_other', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n"
     ]
    }
   ],
   "source": [
    "def preprocess_features(X):\n",
    "    ''' Pré-processa os dados dos estudantes e converte as variáveis binárias não numéricas em\n",
    "        variáveis binárias (0/1). Converte variáveis categóricas em variáveis postiças. '''\n",
    "    \n",
    "    # Inicialize nova saída DataFrame\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "\n",
    "    # Observe os dados em cada coluna de atributos \n",
    "    for col, col_data in X.iteritems():\n",
    "        \n",
    "        # Se o tipo de dado for não numérico, substitua todos os valores yes/no por 1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['yes', 'no'], [1, 0])\n",
    "\n",
    "        # Se o tipo de dado for categórico, converta-o para uma variável dummy\n",
    "        if col_data.dtype == object:\n",
    "            # Example: 'school' => 'school_GP' and 'school_MS'\n",
    "            col_data = pd.get_dummies(col_data, prefix = col)  \n",
    "        \n",
    "        # Reúna as colunas revisadas\n",
    "        output = output.join(col_data)\n",
    "    \n",
    "    return output\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "print(\"Processed feature columns ({} total features):\\n{}\".format(len(X_all.columns), list(X_all.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Divisão dos Dados de Treinamento e Teste\n",
    "Até agora, nós convertemos todos os atributos _categóricos_ em valores numéricos. Para o próximo passo, vamos dividir os dados (tanto atributos como os rótulos correspondentes) em conjuntos de treinamento e teste. Na célula de código abaixo, você irá precisar implementar o seguinte:\n",
    "- Embaralhe aleatoriamente os dados (`X_all`, `y_all`) em subconjuntos de treinamento e teste.\n",
    "  - Utilizar 300 pontos de treinamento (aproxidamente 75%) e 95 pontos de teste (aproximadamente 25%).\n",
    "  - Estabelecer um `random_state` para as funções que você utiliza, se a opção existir.\n",
    "  - Armazene os resultados em `X_train`, `X_test`, `y_train` e `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O conjunto de treinamento tem 300 amostras.\n",
      "O conjunto de teste tem 95 amostras.\n"
     ]
    }
   ],
   "source": [
    "# Importe qualquer funcionalidade adicional de que você possa precisar aqui\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Estabeleça o número de pontos de treinamento\n",
    "num_train = 300\n",
    "\n",
    "#Emabaralhe e distribua o conjunto de dados de acordo com o número de pontos de treinamento e teste abaixo\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, train_size=num_train, random_state=42,stratify=y_all)\n",
    "\n",
    "# Mostre o resultado da distribuição\n",
    "print(\"O conjunto de treinamento tem {} amostras.\".format(X_train.shape[0]))\n",
    "print(\"O conjunto de teste tem {} amostras.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando e Avaliando Modelos\n",
    "Nesta seção, você irá escolher 3 modelos de aprendizagem supervisionada que sejam apropriados para esse problema e que estejam disponíveis no `scikit-learn`. Primeiro você irá discutir o raciocínio por trás da escolha desses três modelos considerando suas vantagens e desvantagens e o que você sabe sobre os dados. Depois você irá ajustar o modelo a diferentes tamanhos de conjuntos de treinamento (com 100, 200 e 300 pontos) e medir a pontuação F<sub>1</sub>. Você vai precisar preencher três tabelas (uma para cada modelo) que mostrem o tamanho do conjunto de treinamento, o tempo de treinamento, o tempo de previsão e a pontuação F<sub>1</sub> no conjunto de treinamento.\n",
    "\n",
    "**Os seguintes modelos de aprendizagem supervisionada estão atualmente disponíveis no **[`scikit-learn`](http://scikit-learn.org/stable/supervised_learning.html)** para você escolher:**\n",
    "- Gaussian Naive Bayes (GaussianNB)\n",
    "- Árvores de Decisão\n",
    "- Métodos de agregação (Bagging, AdaBoost, Random Forest, Gradient Boosting)\n",
    "- K-Nearest Neighbors (KNeighbors)\n",
    "- Método do gradiente estocástico (SGDC)\n",
    "- Máquinas de vetores de suporte (SVM)\n",
    "- Regressão logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 2 - Aplicação dos Modelos\n",
    "*Liste três modelos de aprendizagem supervisionada que são apropriadas para esse problema. Para cada modelo escolhido:*\n",
    "- Descreva uma aplicação em mundo real na indústria em que o modelo pode ser aplicado. *(Talvez você precise fazer um pouco de pesquisa para responder essa questão – dê as devidas referências!)* \n",
    "- Quais são as vantagens do modelo; quando ele tem desempenho melhor? \n",
    "- Quais são as desvantagens do modelo, quando ele tem desempenho pior?\n",
    "- O que faz desse modelo um bom candidato para o problema, considerando o que você sabe sobre os dados?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: **\n",
    "\n",
    "\n",
    "** RandomForestClassifier ** \n",
    "\n",
    "+ **_Aplicação em mundo real na indústria :_**  \n",
    "\n",
    "Random forest é um método de aprendizagem de máquinas altamente versátil, com inúmeras aplicações que vão desde marketing até cuidados de saúde e seguros. Ele pode ser usado para modelar o impacto do marketing na aquisição, retenção e churn do cliente, ou para prever risco de doença e susceptibilidade em pacientes.\n",
    "\n",
    "\n",
    "+ **_Vantagens do modelo:_** \n",
    "\n",
    "Random forest é capaz de regressão e classificação. Ele pode lidar com uma grande quantidade de recursos e é útil para estimar quais das suas variáveis são importantes nos dados subjacentes que estão sendo modelados.\n",
    "\n",
    "\n",
    "\n",
    "+ **_Desvantagens do modelo:_** \n",
    "\n",
    "A principal limitação do algoritmo Random Forest é que um grande número de árvores pode tornar o algoritmo lento para a previsão em tempo real.\n",
    "\n",
    "\n",
    "+ **_O que faz desse modelo um bom candidato:_** \n",
    "\n",
    "Random forest é um algoritmo de classificação supervisionado. Como o nome sugere, esse algoritmo cria a floresta com várias árvores. Em geral, quanto mais árvores na floresta, mais robusta é a floresta. Da mesma forma que no Random Forest Classifier, quanto maior o número de árvores na floresta, melhor a precisão do modelo.\n",
    "\n",
    "\n",
    "+ **_Referências_**\n",
    "\n",
    "http://blog.yhat.com/posts/random-forests-in-python.html\n",
    "\n",
    "https://en.wikipedia.org/wiki/Random_forest\n",
    "\n",
    "https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\n",
    "\n",
    "http://dataaspirant.com/2017/05/22/random-forest-algorithm-machine-learing/\n",
    "\n",
    "\n",
    "------\n",
    "\n",
    "------\n",
    "\n",
    "** SVM **            \n",
    "\n",
    "+ **_Aplicação em mundo real na indústria :_**  \n",
    "\n",
    "SVM é um algoritmo supervisionado de aprendizagem de máquinas que pode ser usado para problemas de classificação ou regressão. Ele usa uma técnica chamada kernel transformation para transformar seus dados e, em seguida, com base nessas transformações, ele encontra um limite ótimo entre as possíveis saídas. Simplificando, ele faz algumas transformações de dados extremamente complexas, então descobre como separar seus dados com base nos labels ou nas saídas que você definiu.\n",
    "\n",
    "  SVM pode ser aplicado em diversas áreas como categorização de texto, classificação de imagens, reconhecimento de caracteres manuscritos.\n",
    "  Na bioinformática o SVM é utilizado na classificação de proteínas e na classificação de doenças como câncer.\n",
    "\n",
    "\n",
    "+ **_Vantagens do modelo:_** \n",
    "\n",
    "Os SVMs são efetivos quando o número de variáveis é consideravelmente grande, mesmo que este seja maior que o número de amostras.\n",
    "\n",
    "Os dados não-lineares também podem ser classificados usando hiperplanos personalizados construídos usando o truque do kernel.\n",
    "\n",
    "É um modelo robusto para resolver problemas de previsão, pois maximiza a margem.\n",
    "\n",
    "\n",
    "+ **_Desvantagens do modelo:_**\n",
    "\n",
    "A maior limitação do SVM é a escolha do kernel. A má escolha do kernel pode levar a um aumento do percentual de erros na predição.\n",
    "\n",
    "Os SVMs têm bom desempenho de generalização, mas podem ser extremamente lentos na fase de teste.\n",
    "\n",
    "Os SVMs possuem alta complexidade algorítmica e requisitos de memória extensivos devido ao uso de programação quadrática.\n",
    "\n",
    "+ **_O que faz desse modelo um bom candidato:_** Uma vez que estamos tentando resolver um problema de classificação binária, o SVM pode ser uma boa escolha por maximizar a margem de hiperplano.\n",
    "\n",
    "\n",
    "+ **_Referências_**\n",
    "\n",
    "http://www.yaksis.com/posts/why-use-svm.html\n",
    "\n",
    "https://en.wikipedia.org/wiki/Support_vector_machine\n",
    "\n",
    "http://web.mit.edu/zoya/www/SVM.pdf\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2015/10/understaing-support-vector-machine-example-code/\n",
    "\n",
    "http://condor.depaul.edu/ntomuro/courses/578/notes/SVM-overview.pdf\n",
    "\n",
    "http://dataaspirant.com/2017/01/13/support-vector-machine-algorithm/\n",
    "\n",
    "------\n",
    "\n",
    "**DecisionTreeClassifier**      \n",
    "\n",
    "+ **_Aplicação em mundo real na indústria :_** \n",
    "\n",
    "Decision Trees podem ser aplicados para a classificação da qualidade de grãos, como por exemplo o café.\n",
    "\n",
    "+ **_Vantagens do modelo:_** \n",
    "\n",
    "\n",
    "Árvores de decisão são resultantes de um conjunto de regras, isto é, seguem a mesma abordagem que os humanos geralmente seguem ao tomar decisões, portanto são fáceis de explicar,  \n",
    "\n",
    "A interpretação de um modelo de Árvore de Decisão complexa pode ser simplificada por suas visualizações. Mesmo uma pessoa ingênua pode entender a lógica.\n",
    "\n",
    "O número de hiper-parâmetros a serem sintonizados é quase nulo.\n",
    "\n",
    "+ **_Desvantagens do modelo:_**\n",
    "\n",
    "Existe uma alta probabilidade de overfitting na Árvore de Decisão.\n",
    "Geralmente, proporciona baixa precisão de previsão para um conjunto de dados em comparação com outros algoritmos de machine learning.\n",
    "\n",
    "O ganho de informação em uma árvore de decisão com variáveis categóricas dá uma resposta tendenciosa para atributos com maior número de categorias.\n",
    "\n",
    "Os cálculos podem se tornar complexos quando há muitos rótulos à serem classificados.\n",
    "\n",
    "+ **_O que faz desse modelo um bom candidato:_**\n",
    "\n",
    "O motivo geral de usar Decision Tree é criar um modelo de treinamento que possa usar para prever a classe ou o valor das variáveis alvo, aprendendo as regras de decisão inferidas a partir de dados anteriores (dados de treinamento).\n",
    "\n",
    "Por ser um modelo de fácil entendimento, se torna eficaz ao explicar seu comportamento e os insights gerados para leigos.\n",
    "\n",
    "\n",
    "+ **_Referências_** \n",
    "\n",
    "http://www.cbcb.umd.edu/~salzberg/docs/murthy_thesis/survey/node32.html\n",
    "\n",
    "http://what-when-how.com/artificial-intelligence/decision-tree-applications-for-data-modelling-artificial-intelligence/\n",
    "\n",
    "\n",
    "https://en.wikipedia.org/wiki/Decision_tree_learning\n",
    "\n",
    "http://dataaspirant.com/2017/01/30/how-decision-tree-algorithm-works/\n",
    "\n",
    "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.90.5327&rep=rep1&type=pdf\n",
    "\n",
    "------\n",
    "**AdaBoostClassifier**      \n",
    "\n",
    "+ **_Aplicação em mundo real na indústria :_** \n",
    "    \n",
    "    \n",
    "O AdaBoost, abreviação de \"Adaptive Boosting\", é um meta-algoritmo de Machine Learning formulado por Yoav Freund e Robert Schapire, que ganhou o Prêmio Gödel em 2003 por seu trabalho. \n",
    "\n",
    "Ele pode ser usado em conjunto com muitos outros tipos de algoritmos de aprendizagem para melhorar seu desempenho. A saída dos outros algoritmos de aprendizagem (\"Weak Learners) é combinada em uma soma ponderada que representa a saída final do classificador reforçado.\n",
    "\n",
    "O AdaBoost é adaptável no sentido de que weak learners subseqüentes são modificados em favor de instâncias mal classificadas por classificadores anteriores.\n",
    "\n",
    "O AdaBoost é sensível a dados ruidosos e outliers. Em alguns problemas, pode ser menos suscetível ao problema de superposição do que outros algoritmos de aprendizado. Os aprendentes individuais podem ser fracos, mas enquanto o desempenho de cada um for um pouco melhor do que o adivinhar aleatoriamente (por exemplo, sua taxa de erro é menor que 0,5 para a classificação binária), o modelo final pode ser comprovado para convergir para um strong learner.\n",
    "\n",
    "+ **_Vantagens do modelo:_** \n",
    "\n",
    "Eficiente computacionalmente.\n",
    "Versatil, uma grande quantidade de classificadores podem ser utilizados com AdaBoost.\n",
    "\n",
    "+ **_Desvantagens do modelo:_**\n",
    "\n",
    "O aprendiz fraco não deve ser muito complexo - para evitar overfitting.\n",
    "O AdaBoost é sensível a dados ruidosos e outliers.\n",
    "\n",
    "+ **_O que faz desse modelo um bom candidato:_**\n",
    "\n",
    "Como este algoritmo tem como objetivo utilizar classificadores (\"weak learners\") para melhorar a acuracidade de um modelo, este pode ser um bom candidato.\n",
    "\n",
    "+ **_Referências_**\n",
    "\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5540979/\n",
    "\n",
    "http://www.inf.fu-berlin.de/inst/ag-ki/adaboost4.pdf\n",
    "\n",
    "http://mccormickml.com/2013/12/13/adaboost-tutorial/\n",
    "\n",
    "http://www.ritchieng.com/machine-learning-ensemble-of-learners-adaboost/\n",
    "\n",
    "------\n",
    "**GaussianNB**           \n",
    "+ **_Aplicação em mundo real na indústria :_** \n",
    "\n",
    "\n",
    "Naive Bayes apresenta bons resultados em utilização para análise textual de dados e processamento de linguagem natural.\n",
    "\n",
    "+ **_Vantagens do modelo:_** \n",
    "\n",
    "Naive Bayes é um algoritmo rápido e altamente escalável.\n",
    "Pode ser usado para classificação binária e de multiplas classes.\n",
    "Pode ser facilmente treinado em pequenos conjuntos de dados.\n",
    "\n",
    "+ **_Desvantagens do modelo:_**\n",
    "\n",
    "Considera que todos as features não estão relacionadas, portanto, não pode aprender a relação entre elas.\n",
    "\n",
    "+ **_O que faz desse modelo um bom candidato:_**\n",
    "\n",
    "Facilidade de implementação.\n",
    "Pode ser facilmente treinado em pequenos conjuntos de dados. \n",
    "\n",
    "+ **_Referências_**\n",
    "\n",
    "http://dataaspirant.com/2017/02/06/naive-bayes-classifier-machine-learning/\n",
    "\n",
    "---\n",
    "\n",
    "https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-algorithm-choice\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuração\n",
    "Execute a célula de código abaixo para inicializar três funções de ajuda que você pode utilizar para treinar e testar os três modelos de aprendizagem supervisionada que você escolheu acima. As funções são as seguintes:\n",
    "- `train_classifier` - recebe como parâmetro um classificador e dados de treinamento e ajusta o classificador aos dados.\n",
    "- `predict_labels` - recebe como parâmetro um classificador ajustado, atributos e rótulo alvo e faz estimativas utilizando a pontuação do F<sub>1</sub>.\n",
    "- `train_predict` - recebe como entrada um classificador, e dados de treinamento e teste, e executa `train_clasifier` e `predict_labels`.\n",
    " - Essa função vai dar a pontuação F<sub>1</sub> tanto para os dados de treinamento como para os de teste, separadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Ajusta um classificador para os dados de treinamento. '''\n",
    "    \n",
    "    # Inicia o relógio, treina o classificador e, então, para o relógio\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Imprime os resultados\n",
    "    print(\"O modelo foi treinado em {:.4f} segundos\".format(end - start))\n",
    "\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Faz uma estimativa utilizando um classificador ajustado baseado na pontuação F1. '''\n",
    "    \n",
    "    # Inicia o relógio, faz estimativas e, então, o relógio para\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time()\n",
    "    \n",
    "    # Imprime os resultados de retorno\n",
    "    print(\"As previsões foram feitas em {:.4f} segundos.\".format(end - start))\n",
    "    return f1_score(target.values, y_pred, pos_label='yes')\n",
    "\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Treina e faz estimativas utilizando um classificador baseado na pontuação do F1. '''\n",
    "    \n",
    "    # Indica o tamanho do classificador e do conjunto de treinamento\n",
    "    print(\"Treinando um {} com {} pontos de treinamento. . .\".format(clf.__class__.__name__, len(X_train)))\n",
    "    \n",
    "    # Treina o classificador\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Imprime os resultados das estimativas de ambos treinamento e teste\n",
    "    print(\"Pontuação F1 para o conjunto de treino: {:.4f}.\".format(predict_labels(clf, X_train, y_train)))\n",
    "    print(\"Pontuação F1 para o conjunto de teste: {:.4f}.\".format(predict_labels(clf, X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Métricas de Desempenho do Modelo\n",
    "Com as funções acima, você vai importar os três modelos de aprendizagem supervisionada de sua escolha e executar a função `train_prediction` para cada um deles. Lembre-se de que você vai precisar treinar e usar cada classificador para três diferentes tamanhos de conjuntos de treinamentos: 100, 200 e 300 pontos. Então você deve ter 9 saídas diferentes abaixo – 3 para cada modelo utilizando cada tamanho de conjunto de treinamento. Na célula de código a seguir, você deve implementar o seguinte:\n",
    "- Importe os três modelos de aprendizagem supervisionada que você escolheu na seção anterior.\n",
    "- Inicialize os três modelos e armazene eles em `clf_A`, `clf_B` e `clf_C`.\n",
    " - Defina um `random_state` para cada modelo, se a opção existir.\n",
    " - **Nota:** Utilize as configurações padrão para cada modelo – você vai calibrar um modelo específico em uma seção posterior.\n",
    "- Crie diferentes tamanhos de conjuntos de treinamento para treinar cada modelo.\n",
    " - *Não embaralhe e distribua novamente os dados! Os novos pontos de treinamento devem ser tirados de `X_train` e `y_train`.*\n",
    "- Treine cada modelo com cada tamanho de conjunto de treinamento e faça estimativas com o conjunto de teste (9 vezes no total).  \n",
    "**Nota:** Três tabelas são fornecidas depois da célula de código a seguir, nas quais você deve anotar seus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############### RandomForestClassifier #######################\n",
      "Treinando um RandomForestClassifier com 100 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0353 segundos\n",
      "As previsões foram feitas em 0.0037 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.9848.\n",
      "As previsões foram feitas em 0.0034 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.6984.\n",
      "_____________________________________________________\n",
      "Treinando um RandomForestClassifier com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0361 segundos\n",
      "As previsões foram feitas em 0.0040 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.9845.\n",
      "As previsões foram feitas em 0.0037 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7368.\n",
      "_____________________________________________________\n",
      "Treinando um RandomForestClassifier com 300 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0380 segundos\n",
      "As previsões foram feitas em 0.0042 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.9828.\n",
      "As previsões foram feitas em 0.0034 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7612.\n",
      "_____________________________________________________\n",
      "\n",
      "############### SVC #######################\n",
      "Treinando um SVC com 100 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0050 segundos\n",
      "As previsões foram feitas em 0.0033 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8354.\n",
      "As previsões foram feitas em 0.0031 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.8025.\n",
      "_____________________________________________________\n",
      "Treinando um SVC com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0139 segundos\n",
      "As previsões foram feitas em 0.0111 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8431.\n",
      "As previsões foram feitas em 0.0055 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.8105.\n",
      "_____________________________________________________\n",
      "Treinando um SVC com 300 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0268 segundos\n",
      "As previsões foram feitas em 0.0210 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8664.\n",
      "As previsões foram feitas em 0.0070 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.8052.\n",
      "_____________________________________________________\n",
      "\n",
      "############### DecisionTreeClassifier #######################\n",
      "Treinando um DecisionTreeClassifier com 100 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0026 segundos\n",
      "As previsões foram feitas em 0.0007 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 1.0000.\n",
      "As previsões foram feitas em 0.0007 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.6667.\n",
      "_____________________________________________________\n",
      "Treinando um DecisionTreeClassifier com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0038 segundos\n",
      "As previsões foram feitas em 0.0007 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 1.0000.\n",
      "As previsões foram feitas em 0.0009 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7097.\n",
      "_____________________________________________________\n",
      "Treinando um DecisionTreeClassifier com 300 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0051 segundos\n",
      "As previsões foram feitas em 0.0008 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 1.0000.\n",
      "As previsões foram feitas em 0.0007 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.6557.\n",
      "_____________________________________________________\n",
      "\n",
      "############### AdaBoostClassifier #######################\n",
      "Treinando um AdaBoostClassifier com 100 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.1872 segundos\n",
      "As previsões foram feitas em 0.0148 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.9778.\n",
      "As previsões foram feitas em 0.0145 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.6880.\n",
      "_____________________________________________________\n",
      "Treinando um AdaBoostClassifier com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.1942 segundos\n",
      "As previsões foram feitas em 0.0194 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8905.\n",
      "As previsões foram feitas em 0.0146 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7445.\n",
      "_____________________________________________________\n",
      "Treinando um AdaBoostClassifier com 300 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.2073 segundos\n",
      "As previsões foram feitas em 0.0223 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8565.\n",
      "As previsões foram feitas em 0.0144 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7328.\n",
      "_____________________________________________________\n",
      "\n",
      "############### GaussianNB #######################\n",
      "Treinando um GaussianNB com 100 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0027 segundos\n",
      "As previsões foram feitas em 0.0011 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.7752.\n",
      "As previsões foram feitas em 0.0012 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.6457.\n",
      "_____________________________________________________\n",
      "Treinando um GaussianNB com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0029 segundos\n",
      "As previsões foram feitas em 0.0012 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8060.\n",
      "As previsões foram feitas em 0.0011 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7218.\n",
      "_____________________________________________________\n",
      "Treinando um GaussianNB com 300 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0028 segundos\n",
      "As previsões foram feitas em 0.0015 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8134.\n",
      "As previsões foram feitas em 0.0014 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7761.\n",
      "_____________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Importe os três modelos de aprendizagem supervisionada do sklearn\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier  # Métodos de agregação (Random Forest)\n",
    "from sklearn import svm                              # Máquinas de vetores de suporte (SVM) \n",
    "from sklearn.tree import DecisionTreeClassifier      # Árvores de Decisão\n",
    "from sklearn.ensemble import AdaBoostClassifier      # Métodos de agregação ( AdaBoost )\n",
    "from sklearn.naive_bayes import GaussianNB           # Gaussian Naive Bayes (GaussianNB)\n",
    "\n",
    "#Inicialize os três modelos\n",
    "clf_A = RandomForestClassifier(random_state=0)\n",
    "clf_B = svm.SVC(random_state=0)\n",
    "clf_C = DecisionTreeClassifier(random_state=0)\n",
    "clf_D = AdaBoostClassifier(random_state=0)\n",
    "clf_E = GaussianNB()\n",
    "\n",
    "classifiers = [clf_A, clf_B, clf_C,clf_D,clf_E]\n",
    "train_sets = [100, 200, 300]\n",
    "\n",
    "#Executar a função 'train_predict' para cada classificador e cada tamanho de conjunto de treinamento\n",
    "for clf in classifiers:\n",
    "    print(\"\\n############### {} #######################\".format(clf.__class__.__name__))\n",
    "    for n_train in train_sets:\n",
    "        train_predict(clf, X_train[:n_train], y_train[:n_train], X_test, y_test)\n",
    "        print(\"_____________________________________________________\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados Tabulados\n",
    "Edite a célula abaixo e veja como a tabela pode ser desenhada em [Markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet#tables). Você deve salvar seus resultados abaixo nas tabelas fornecidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Classificador 1 - RandomForestClassifier**  \n",
    "\n",
    "| Tamanho do Conjunto de Treinamento | Tempo de Treinamento | Tempo de Estimativa (teste) | Pontuação F1 (treinamento) | Pontuação F1 (teste) |\n",
    "| :--------------------------------: | :------------------: | :-------------------------: | :------------------------: | :------------------: |\n",
    "| 100                                |       0.0355         |          0.0425             |          0.9922            |        0.6614        |\n",
    "| 200                                |       0.0359         |          0.0431             |          0.9964            |        0.7536        |\n",
    "| 300                                |       0.0375         |          0.0449             |          0.9927            |        0.7407        |\n",
    "\n",
    "** Classificador 2 - SVM**  \n",
    "\n",
    "| Tamanho do Conjunto de Treinamento | Tempo de Treinamento | Tempo de Estimativa (teste) | Pontuação F1 (treinamento) | Pontuação F1 (teste) |\n",
    "| :--------------------------------: | :------------------: | :-------------------------: | :------------------------: | :------------------: |\n",
    "| 100                                |      0.0048          |           0.0114            |          0.8777            |       0.7746         |\n",
    "| 200                                |      0.0122          |           0.0269            |          0.8679            |       0.7815         |\n",
    "| 300                                |      0.0169          |           0.0565            |          0.8761            |       0.7838         |\n",
    "\n",
    "** Classificador 3 - DecisionTreeClassifier**  \n",
    "\n",
    "| Tamanho do Conjunto de Treinamento | Tempo de Treinamento | Tempo de Estimativa (teste) | Pontuação F1 (treinamento) | Pontuação F1 (teste) |\n",
    "| :--------------------------------: | :------------------: | :-------------------------: | :------------------------: | :------------------: |\n",
    "| 100                                |       0.0026         |        0,0040               |           1.0000           |         0.6154       |\n",
    "| 200                                |       0.0041         |        0,0060               |           1.0000           |         0.7040       |\n",
    "| 300                                |       0.0054         |        0,0075               |           1.0000           |         0.6102       |\n",
    "\n",
    "** Classificador 4 - AdaBoostClassifier**  \n",
    "\n",
    "| Tamanho do Conjunto de Treinamento | Tempo de Treinamento | Tempo de Estimativa (teste) | Pontuação F1 (treinamento) | Pontuação F1 (teste) |\n",
    "| :--------------------------------: | :------------------: | :-------------------------: | :------------------------: | :------------------: |\n",
    "| 100                                |       0.1354         |        0.2498               |           0.9481           |         0.7669       |\n",
    "| 200                                |       0.1404         |        0.2586               |           0.8927           |         0.8281       |\n",
    "| 300                                |       0.1375         |        0.2759               |           0.8637           |         0.7820       |\n",
    "** Classificador 5 - Naive Bayes (GaussianNB) **\n",
    "\n",
    "| Tamanho do Conjunto de Treinamento | Tempo de Treinamento | Tempo de Estimativa (teste) | Pontuação F1 (treinamento) | Pontuação F1 (teste) |\n",
    "| :--------------------------------: | :------------------: | :-------------------------: | :------------------------: | :------------------: |\n",
    "| 100                                |       0.0020         |        0.0070               |           0.8467           |         0.8029       |\n",
    "| 200                                |       0.0026         |        0.0068               |           0.8406           |         0.7244       |\n",
    "| 300                                |       0.0033         |        0.0066               |           0.8038           |         0.7634       |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escolhendo o Melhor Modelo\n",
    "Nesta seção final, você irá escolher dos três modelos de aprendizagem supervisionada o *melhor* para utilizar os dados dos estudantes. Você então executará um busca em matriz otimizada para o modelo em todo o conjunto de treinamento (`X_train` e `y_train`) ao calibrar pelo menos um parâmetro, melhorando em comparação a pontuação F<sub>1</sub> do modelo não calibrado. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 3 - Escolhendo o Melhor Modelo\n",
    "*Baseando-se nos experimentos que você executou até agora, explique em um ou dois parágrafos ao conselho de supervisores qual modelo que você escolheu como o melhor. Qual modelo é o mais apropriado baseado nos dados disponíveis, recursos limitados, custo e desempenho?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conforme revisão anterior, peço que você considere também o tempo necessário para treinar o modelo e realizar previsões ao discutir qual modelo você escolheu para calibrar.\n",
    "\n",
    "\n",
    "**Resposta: **\n",
    "\n",
    "   Por apresentar uma boa performance de tempo de treinamento 0.0169 segundos e tempo total de 0.0565 segundos para um conjunto de treinamento de 300 observações, pode se considerar o SVM como um modelo robusto para a utilização neste conjunto de dados. \n",
    "  Sua performance como modelo preditivo é apresentado através dos F1 scores iniciais, isto é, sem utilização de hiperparametros, de 0.8761 para treinamento e 0.7838 para testes.\n",
    "  \n",
    "  É importante destacar que o tempo de treinamento e testes dos modelos GaussianNB e DecisionTreeClassifier foram melhores, entretanto como a premissa do exercicio era a não utilização de hiperparametros, estes não apresentaram F1 scores melhores que o SVM, sendo assim este eleito o \"melhor\" modelo nesta etapa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 4 – O Modelo para um Leigo\n",
    "*Em um ou dois parágrafos, explique para o conselho de supervisores, utilizando termos leigos, como o modelo final escolhido deve trabalhar. Tenha certeza que você esteja descrevendo as melhores qualidades do modelo, por exemplo, como o modelo é treinado e como ele faz uma estimativa. Evite jargões técnicos ou matemáticos, como descrever equações ou discutir a implementação do algoritmo.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: **\n",
    "\n",
    "Uma máquina de vetores de suporte (SVM, do inglês: support vector machine) é um conceito na ciência da computação para um conjunto de métodos do aprendizado supervisionado que analisam os dados e reconhecem padrões, usado para classificação e análise de regressão. O SVM padrão toma como entrada um conjunto de dados e prediz, para cada entrada dada, qual de duas possíveis classes a entrada faz parte.\n",
    "\n",
    "Dados um conjunto de exemplos de treinamento, cada um marcado como pertencente a uma de duas categorias, um algoritmo de treinamento do SVM constrói um modelo que atribui novos exemplos a uma categoria ou outra. Um modelo SVM é uma representação de exemplos como pontos no espaço, mapeados de maneira que os exemplos de cada categoria sejam divididos por um espaço claro que seja tão amplo quanto possível. Os novos exemplos são então mapeados no mesmo espaço e preditos como pertencentes a uma categoria baseados em qual o lado do espaço eles são colocados.\n",
    "\n",
    "Em outras palavras, o que uma SVM faz é encontrar uma linha de separação, mais comumente chamada de hiperplano entre dados de duas classes. Essa linha busca maximizar a distância entre os pontos mais próximos em relação a cada uma das classe:\n",
    "\n",
    "Entretanto, se os dados de treinamento não forem linearmente separáveis, o hiperplano obtido pelo classificador pode ter baixo poder de generalização, mesmo que o hiperplano seja determinado de maneira ótima. Assim, para melhor a separabilidade linear, o espaço original é mapeado em um espaço de dimensão mais alta conhecido como espaço de características atráves de um metodo chamado kernel trick. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Calibrando o Modelo\n",
    "Calibre o modelo escolhido. Utilize busca em matriz (`GridSearchCV`) com, pelo menos, um parâmetro importante calibrado com, pelo menos, 3 valores diferentes. Você vai precisar utilizar todo o conjunto de treinamento para isso. Na célula de código abaixo, você deve implementar o seguinte:\n",
    "- Importe [`sklearn.grid_search.gridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html) e [`sklearn.metrics.make_scorer`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html).\n",
    "- Crie o dicionário de parâmetros que você deseja calibrar para o modelo escolhido.\n",
    " - Examplo: `parameters = {'parameter' : [list of values]}`.\n",
    "- Inicialize o classificador que você escolheu e armazene-o em `clf`.\n",
    "- Crie a função de pontuação F<sub>1</sub> utilizando `make_scorer` e armazene-o em `f1_scorer`.\n",
    " - Estabeleça o parâmetro `pos_label` para o valor correto!\n",
    "- Execute uma busca em matriz no classificador `clf` utilizando o `f1_scorer` como método de pontuação e armazene-o em `grid_obj`.\n",
    "- Treine o objeto de busca em matriz com os dados de treinamento (`X_train`, `y_train`) e armazene-o em `grid_obj`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=1, gamma='auto', kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=42, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "As previsões foram feitas em 0.0085 segundos.\n",
      "O modelo calibrado tem F1 de 0.8319 no conjunto de treinamento.\n",
      "As previsões foram feitas em 0.0032 segundos.\n",
      "O modelo calibrado tem F1 de 0.7947 no conjunto de teste.\n"
     ]
    }
   ],
   "source": [
    "#Importe 'GridSearchCV' e 'make_scorer'\n",
    "from sklearn import svm\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "    \n",
    "#Crie a lista de parâmetros que você gostaria de calibrar\n",
    "parameters = [\n",
    "    {'C': [0.1, 1, 10], 'kernel': ['linear']},\n",
    "    {'C': [0.1, 1, 10], 'degree':[1, 2, 3], 'kernel': ['poly']},\n",
    "    {'C': [0.1, 1, 10], 'gamma': [0.5, 0.1, 0.01], 'kernel': ['rbf']}\n",
    "]\n",
    "\n",
    "#Inicialize o classificador\n",
    "clf = svm.SVC(random_state=42,kernel='rbf')\n",
    "\n",
    "#Faça uma função de pontuação f1 utilizando 'make_scorer' \n",
    "f1_scorer = make_scorer(f1_score, pos_label=\"yes\")\n",
    "\n",
    "# Execute uma busca em matriz no classificador utilizando o f1_scorer como método de pontuação\n",
    "grid_obj = GridSearchCV(clf, parameters,scoring=f1_scorer,cv=9)\n",
    "\n",
    "# TODO: Ajuste o objeto de busca em matriz para o treinamento de dados e encontre os parâmetros ótimos\n",
    "grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Get the estimator\n",
    "clf = grid_obj.best_estimator_\n",
    "\n",
    "print(clf)\n",
    "# Reporte a pontuação final F1 para treinamento e teste depois de calibrar os parâmetrosprint \"Tuned model has a training F1 score of {:.4f}.\".format(predict_labels(clf, X_train, y_train))\n",
    "print(\"O modelo calibrado tem F1 de {:.4f} no conjunto de treinamento.\".format(predict_labels(clf, X_train, y_train)))\n",
    "print(\"O modelo calibrado tem F1 de {:.4f} no conjunto de teste.\".format(predict_labels(clf, X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f64e164dac8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAyIAAAJbCAYAAAAYFyDjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAIDeKUQAAIDeKUQAAIDe/T+FYgI9cjlinwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f64e7334668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "cm_test = confusion_matrix(y_test, clf.predict(X_test))\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(cm_test, annot=True, cmap='Greys', xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
    "plt.title('Confusion Matrix for the Test Set')\n",
    "plt.ylabel('True')\n",
    "plt.xlabel('Predicted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 5 - Pontuação F<sub>1</sub> Final\n",
    "*Qual é a pontuação F<sub>1</sub> do modelo final para treinamento e teste? Como ele se compara ao modelo que não foi calibrado?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: ** A pontuação F1 do modelo final foi de 0.8423 no conjunto de treinamento e 0.7838 no conjunto de teste. \n",
    "   Apesar de utilizado o GridSearchCV com vários parâmetros e o modelo ter levado muito mais tempo de treinamento, não se obteve ganho de pontuação se comparado ao que não foi calibrado no exercício anterior.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Nota**: Uma vez que você completou todas as implementações de código e respondeu todas as questões acima com êxito, você pode finalizar seu trabalho exportando o iPython Nothebook como um document HTML. Você pode fazer isso utilizando o menu acima e navegando para  \n",
    "**File -> Download as -> HTML (.html)**. Inclua a documentação final junto com o notebook para o envio do seu projeto."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
